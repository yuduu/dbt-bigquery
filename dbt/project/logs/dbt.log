

============================== 2022-09-02 07:49:08.815252 | 7124519f-6d27-4d30-aa92-872e18988af1 ==============================
[0m07:49:08.815265 [info ] [MainThread]: Running with dbt=1.2.1
[0m07:49:08.815492 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:49:08.815580 [debug] [MainThread]: Tracking: tracking
[0m07:49:08.817203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5ed185b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5ed186a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5ed18790>]}
[0m07:49:08.829317 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
[0m07:49:08.829523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7124519f-6d27-4d30-aa92-872e18988af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5ed1ad70>]}
[0m07:49:08.838293 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:49:08.839935 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:49:08.858105 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:49:08.862703 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:49:08.864587 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:49:08.866660 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:49:08.867782 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:49:08.880409 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:49:08.884496 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:49:08.887406 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:49:08.889344 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:49:08.890049 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:49:08.891027 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:49:08.891941 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:49:08.892347 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:49:08.892627 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:49:08.893037 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:49:08.893397 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:49:08.893820 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:49:08.894186 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:49:08.894570 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:49:08.894792 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:49:08.895008 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:49:08.895355 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:49:08.903328 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:49:08.918280 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:49:08.921855 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:49:08.924350 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:49:08.937120 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:49:08.939951 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:49:08.942264 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:49:08.949874 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:49:08.952923 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:49:08.954665 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:49:08.956320 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:49:08.965121 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:49:08.968562 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:49:08.969121 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:49:08.969696 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:49:08.970311 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:49:08.971299 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:49:08.972948 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:49:08.975771 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:49:08.977141 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:49:08.978527 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:49:08.981921 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:49:08.994980 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:49:09.000045 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:49:09.001309 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:49:09.009898 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:49:09.022011 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:49:09.030959 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:49:09.042027 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:49:09.053566 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:49:09.060471 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:49:09.061543 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:49:09.064719 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:49:09.067185 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:49:09.068086 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:49:09.071959 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:49:09.073695 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:49:09.075723 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:49:09.079760 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:49:09.081371 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:49:09.082804 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:49:09.083464 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:49:09.084326 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:49:09.085036 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:49:09.085678 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:49:09.086337 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:49:09.087187 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:49:09.088009 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:49:09.089260 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:49:09.089883 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:49:09.090542 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:49:09.091276 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:49:09.091963 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:49:09.092686 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:49:09.093675 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:49:09.094386 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:49:09.098438 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:49:09.098985 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:49:09.099516 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:49:09.100255 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:49:09.283959 [debug] [MainThread]: 1699: static parser successfully parsed customers.sql
[0m07:49:09.316079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7124519f-6d27-4d30-aa92-872e18988af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5eb419c0>]}
[0m07:49:09.320645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7124519f-6d27-4d30-aa92-872e18988af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5ed1a6e0>]}
[0m07:49:09.320868 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m07:49:09.321012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7124519f-6d27-4d30-aa92-872e18988af1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e60705930>]}
[0m07:49:09.321829 [info ] [MainThread]: 
[0m07:49:09.322238 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:49:09.323003 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f}"
[0m07:49:09.323160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:09.828899 [debug] [ThreadPool]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest("GET https://bigquery.googleapis.com/bigquery/v2/projects/bt-pp-cus-c84f%7D/datasets?maxResults=10000&prettyPrint=false: Invalid project ID 'bt-pp-cus-c84f}'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.")
[0m07:49:10.932586 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:49:10.933059 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f}' was properly closed.
[0m07:49:10.933511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5eb7e2f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5eb7d960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e5eb666e0>]}
[0m07:49:10.933936 [debug] [MainThread]: Flushing usage events
[0m07:49:11.417938 [error] [MainThread]: Encountered an error:
Database Error
  Invalid project ID 'bt-pp-cus-c84f}'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.
[0m07:49:11.420221 [error] [MainThread]: Traceback (most recent call last):
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/connections.py", line 194, in exception_handler
    yield
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/connections.py", line 611, in _retry_and_handle
    return retry.retry_target(
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/retry.py", line 190, in retry_target
    return target()
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/impl.py", line 186, in query_schemas
    return [ds.dataset_id for ds in all_datasets]
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/impl.py", line 186, in <listcomp>
    return [ds.dataset_id for ds in all_datasets]
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/page_iterator.py", line 208, in _items_iter
    for page in self._page_iter(increment=False):
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/page_iterator.py", line 244, in _page_iter
    page = self._next_page()
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/page_iterator.py", line 373, in _next_page
    response = self._get_next_page_response()
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/page_iterator.py", line 432, in _get_next_page_response
    return self.api_request(
  File "/home/dbt/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py", line 440, in api_request
    return self._call_api(
  File "/home/dbt/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py", line 782, in _call_api
    return call()
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/retry.py", line 283, in retry_wrapped_func
    return retry_target(
  File "/home/dbt/.local/lib/python3.10/site-packages/google/api_core/retry.py", line 190, in retry_target
    return target()
  File "/home/dbt/.local/lib/python3.10/site-packages/google/cloud/_http/__init__.py", line 494, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/bt-pp-cus-c84f%7D/datasets?maxResults=10000&prettyPrint=false: Invalid project ID 'bt-pp-cus-c84f}'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/main.py", line 129, in main
    results, succeeded = handle_and_check(args)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/main.py", line 191, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/main.py", line 238, in run_from_args
    results = task.run()
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/task/runnable.py", line 470, in run
    result = self.execute_with_hooks(selected_uids)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/task/runnable.py", line 432, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/task/run.py", line 442, in before_run
    self.create_schemas(adapter, required_schemas)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/task/runnable.py", line 555, in create_schemas
    existing_schemas_lowered.update(ls_future.result())
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 439, in result
    return self.__get_result()
  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/utils.py", line 480, in connected
    return func(*args, **kwargs)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/task/runnable.py", line 532, in list_schemas
    for s in adapter.list_schemas(database_quoted)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/impl.py", line 188, in list_schemas
    return self.connections._retry_and_handle(msg="list dataset", conn=conn, fn=query_schemas)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/connections.py", line 610, in _retry_and_handle
    with self.exception_handler(msg):
  File "/usr/local/lib/python3.10/contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/connections.py", line 198, in exception_handler
    self.handle_error(e, message)
  File "/home/dbt/.local/lib/python3.10/site-packages/dbt/adapters/bigquery/connections.py", line 186, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Invalid project ID 'bt-pp-cus-c84f}'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.



============================== 2022-09-02 08:00:30.288027 | d0e725bb-97e7-49f1-b5af-25f57ac9adc4 ==============================
[0m08:00:30.288037 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:00:30.288286 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:00:30.288409 [debug] [MainThread]: Tracking: tracking
[0m08:00:30.289898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b1e45b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b1e46d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b1e7df0>]}
[0m08:00:30.310633 [info ] [MainThread]: Unable to do partial parsing because env vars used in profiles.yml have changed
[0m08:00:30.310943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b1e58a0>]}
[0m08:00:30.322983 [debug] [MainThread]: Parsing macros/etc.sql
[0m08:00:30.324554 [debug] [MainThread]: Parsing macros/adapters.sql
[0m08:00:30.342637 [debug] [MainThread]: Parsing macros/catalog.sql
[0m08:00:30.347910 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m08:00:30.349926 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m08:00:30.351993 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m08:00:30.353242 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m08:00:30.365460 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m08:00:30.369510 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m08:00:30.372482 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m08:00:30.374997 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m08:00:30.376098 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m08:00:30.377091 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m08:00:30.377952 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m08:00:30.378339 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m08:00:30.378619 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m08:00:30.379069 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m08:00:30.379407 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m08:00:30.379827 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m08:00:30.380231 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m08:00:30.380757 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m08:00:30.381111 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m08:00:30.381340 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m08:00:30.381672 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m08:00:30.388958 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m08:00:30.399413 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m08:00:30.402705 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m08:00:30.404789 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m08:00:30.414680 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m08:00:30.416640 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m08:00:30.418284 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m08:00:30.423456 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m08:00:30.425218 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m08:00:30.426335 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m08:00:30.427341 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m08:00:30.433367 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m08:00:30.436705 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m08:00:30.437184 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m08:00:30.437722 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m08:00:30.438290 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m08:00:30.439235 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m08:00:30.440806 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m08:00:30.443498 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m08:00:30.444872 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m08:00:30.446258 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m08:00:30.449463 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m08:00:30.462119 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m08:00:30.467223 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m08:00:30.468349 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m08:00:30.476722 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m08:00:30.488591 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m08:00:30.497467 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m08:00:30.508254 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m08:00:30.519774 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m08:00:30.526607 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m08:00:30.527795 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m08:00:30.531062 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m08:00:30.533444 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m08:00:30.534315 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m08:00:30.538296 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m08:00:30.539882 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m08:00:30.541885 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m08:00:30.545970 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m08:00:30.547681 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m08:00:30.549119 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m08:00:30.549742 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m08:00:30.550575 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m08:00:30.551290 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m08:00:30.551911 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m08:00:30.552525 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m08:00:30.553375 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m08:00:30.554202 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m08:00:30.555434 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m08:00:30.556068 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m08:00:30.556742 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m08:00:30.557486 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m08:00:30.558183 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m08:00:30.558975 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m08:00:30.559818 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m08:00:30.560502 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m08:00:30.564476 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m08:00:30.565015 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m08:00:30.565542 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m08:00:30.566282 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m08:00:30.749458 [debug] [MainThread]: 1699: static parser successfully parsed customers.sql
[0m08:00:30.781962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b19be50>]}
[0m08:00:30.786350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b1e45b0>]}
[0m08:00:30.786538 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:00:30.786679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928cbf11b0>]}
[0m08:00:30.787474 [info ] [MainThread]: 
[0m08:00:30.787838 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:00:30.788531 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:00:30.788711 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:00:31.340858 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:00:31.341554 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:00:31.732215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928b014f10>]}
[0m08:00:31.733193 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:00:31.733701 [info ] [MainThread]: 
[0m08:00:31.762136 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:00:31.762469 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:00:31.762798 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:00:31.762903 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:00:31.762997 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:00:31.765273 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:00:31.765643 [debug] [Thread-1 (]: finished collecting timing info
[0m08:00:31.765746 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:00:31.790836 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:00:31.791272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:00:31.792108 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:00:32.514880 [debug] [Thread-1 (]: finished collecting timing info
[0m08:00:32.515890 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:00:32.524890 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0e725bb-97e7-49f1-b5af-25f57ac9adc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9289ec0790>]}
[0m08:00:32.525770 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.76s]
[0m08:00:32.526709 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:00:32.529571 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:00:32.530191 [info ] [MainThread]: 
[0m08:00:32.530579 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m08:00:32.531052 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:00:32.531279 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:00:32.531467 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:00:32.538300 [info ] [MainThread]: 
[0m08:00:32.538550 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:00:32.538740 [info ] [MainThread]: 
[0m08:00:32.538907 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:00:32.539089 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:00:32.539227 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:00:32.539439 [info ] [MainThread]: 
[0m08:00:32.539635 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:00:32.539944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9289e2ff40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f928afb34c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9289edcd60>]}
[0m08:00:32.540162 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:10:21.538650 | d2dcffbb-4434-4429-afd8-7d806a2d8bc9 ==============================
[0m08:10:21.538660 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:10:21.538874 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:10:21.538962 [debug] [MainThread]: Tracking: tracking
[0m08:10:21.540453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226afec5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226afec6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226afec790>]}
[0m08:10:21.566508 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:10:21.566660 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:10:21.570986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2dcffbb-4434-4429-afd8-7d806a2d8bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae6bf40>]}
[0m08:10:21.575919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2dcffbb-4434-4429-afd8-7d806a2d8bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae4c400>]}
[0m08:10:21.576154 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:10:21.576336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2dcffbb-4434-4429-afd8-7d806a2d8bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae4c490>]}
[0m08:10:21.577228 [info ] [MainThread]: 
[0m08:10:21.577656 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:10:21.578377 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:10:21.578580 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:10:22.142327 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:10:22.143219 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:10:22.544400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2dcffbb-4434-4429-afd8-7d806a2d8bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae37be0>]}
[0m08:10:22.545064 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:10:22.545395 [info ] [MainThread]: 
[0m08:10:22.561001 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:10:22.561234 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:10:22.561583 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:10:22.561703 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:10:22.561785 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:10:22.563181 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:10:22.563381 [debug] [Thread-1 (]: finished collecting timing info
[0m08:10:22.563460 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:10:22.588450 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:10:22.588765 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:10:22.589652 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:10:23.334733 [debug] [Thread-1 (]: finished collecting timing info
[0m08:10:23.335575 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:10:23.336191 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2dcffbb-4434-4429-afd8-7d806a2d8bc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226acd9090>]}
[0m08:10:23.336652 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.77s]
[0m08:10:23.337033 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:10:23.338644 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:10:23.338993 [info ] [MainThread]: 
[0m08:10:23.339267 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.76 seconds (1.76s).
[0m08:10:23.339464 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:10:23.339579 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:10:23.339672 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:10:23.345782 [info ] [MainThread]: 
[0m08:10:23.346449 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:10:23.346630 [info ] [MainThread]: 
[0m08:10:23.346777 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:10:23.346943 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:10:23.347216 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:10:23.347431 [info ] [MainThread]: 
[0m08:10:23.347674 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:10:23.347985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae379a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ae68910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f226ac87be0>]}
[0m08:10:23.348362 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:12:57.289912 | cf0cfc81-7c0d-40a7-996f-0cca94361872 ==============================
[0m08:12:57.289922 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:12:57.290190 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:12:57.290275 [debug] [MainThread]: Tracking: tracking
[0m08:12:57.291835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ff1f85b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ff1f86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ff1fbf40>]}
[0m08:12:57.318305 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:12:57.318479 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:12:57.322641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf0cfc81-7c0d-40a7-996f-0cca94361872', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ff0665c0>]}
[0m08:12:57.327818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cf0cfc81-7c0d-40a7-996f-0cca94361872', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8fefdbdf0>]}
[0m08:12:57.328228 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:12:57.328414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf0cfc81-7c0d-40a7-996f-0cca94361872', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8fefdbe80>]}
[0m08:12:57.329368 [info ] [MainThread]: 
[0m08:12:57.329796 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:12:57.330564 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:12:57.330868 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:12:57.847962 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:12:57.848206 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:12:58.244268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cf0cfc81-7c0d-40a7-996f-0cca94361872', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8fee72380>]}
[0m08:12:58.244860 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:12:58.245155 [info ] [MainThread]: 
[0m08:12:58.262265 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:12:58.262577 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:12:58.262968 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:12:58.263083 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:12:58.263162 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:12:58.264956 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:12:58.265165 [debug] [Thread-1 (]: finished collecting timing info
[0m08:12:58.265252 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:12:58.292599 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:12:58.293051 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:12:58.294321 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:12:59.011002 [debug] [Thread-1 (]: finished collecting timing info
[0m08:12:59.011698 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:12:59.012128 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf0cfc81-7c0d-40a7-996f-0cca94361872', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8feeebb50>]}
[0m08:12:59.012684 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.75s]
[0m08:12:59.013439 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:12:59.015177 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:12:59.015572 [info ] [MainThread]: 
[0m08:12:59.015770 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.69 seconds (1.69s).
[0m08:12:59.015962 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:12:59.016083 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:12:59.016148 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:12:59.022234 [info ] [MainThread]: 
[0m08:12:59.022515 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:12:59.022754 [info ] [MainThread]: 
[0m08:12:59.022927 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:12:59.023108 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:12:59.023736 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:12:59.023970 [info ] [MainThread]: 
[0m08:12:59.024196 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:12:59.024687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ff1fb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8fefd90c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8feebba00>]}
[0m08:12:59.024922 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:14:03.079617 | 907b87b9-5985-4a76-bedc-4179b9ac1314 ==============================
[0m08:14:03.079626 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:14:03.079854 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:14:03.079939 [debug] [MainThread]: Tracking: tracking
[0m08:14:03.081585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a3f85b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a3f86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a3f8790>]}
[0m08:14:03.110461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:14:03.110679 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:14:03.120798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '907b87b9-5985-4a76-bedc-4179b9ac1314', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a2780d0>]}
[0m08:14:03.127887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '907b87b9-5985-4a76-bedc-4179b9ac1314', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a258550>]}
[0m08:14:03.128125 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:14:03.128307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '907b87b9-5985-4a76-bedc-4179b9ac1314', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a2585e0>]}
[0m08:14:03.129615 [info ] [MainThread]: 
[0m08:14:03.130125 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:14:03.130994 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:14:03.131359 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:14:03.620476 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:14:03.620855 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:14:04.011625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '907b87b9-5985-4a76-bedc-4179b9ac1314', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a258220>]}
[0m08:14:04.012256 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:14:04.012643 [info ] [MainThread]: 
[0m08:14:04.029208 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:14:04.029445 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:14:04.029788 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:14:04.029911 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:14:04.030025 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:14:04.031390 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:14:04.031578 [debug] [Thread-1 (]: finished collecting timing info
[0m08:14:04.031662 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:14:04.056501 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:14:04.056837 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:14:04.057734 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:14:04.858774 [debug] [Thread-1 (]: finished collecting timing info
[0m08:14:04.859424 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:14:04.859740 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '907b87b9-5985-4a76-bedc-4179b9ac1314', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a27ab00>]}
[0m08:14:04.860278 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.83s]
[0m08:14:04.860731 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:14:04.862435 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:14:04.862941 [info ] [MainThread]: 
[0m08:14:04.863228 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.73 seconds (1.73s).
[0m08:14:04.863503 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:14:04.863602 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:14:04.863677 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:14:04.869103 [info ] [MainThread]: 
[0m08:14:04.869427 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:14:04.869638 [info ] [MainThread]: 
[0m08:14:04.869814 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:14:04.870025 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:14:04.870220 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:14:04.870410 [info ] [MainThread]: 
[0m08:14:04.870590 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:14:04.870935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a2581f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a258250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8a09bd60>]}
[0m08:14:04.871167 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:15:19.281910 | 29c1cd67-eb99-45c4-b4cc-30f1461499c1 ==============================
[0m08:15:19.281919 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:15:19.282150 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:15:19.282272 [debug] [MainThread]: Tracking: tracking
[0m08:15:19.284020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa63809c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa63809c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa63809c790>]}
[0m08:15:19.310644 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:15:19.310798 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:15:19.315023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29c1cd67-eb99-45c4-b4cc-30f1461499c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637efe620>]}
[0m08:15:19.320238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29c1cd67-eb99-45c4-b4cc-30f1461499c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637e73e50>]}
[0m08:15:19.320492 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:15:19.320643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29c1cd67-eb99-45c4-b4cc-30f1461499c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637e73ee0>]}
[0m08:15:19.321549 [info ] [MainThread]: 
[0m08:15:19.321969 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:15:19.322718 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:15:19.322966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:15:19.850685 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:15:19.851106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:15:20.280565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29c1cd67-eb99-45c4-b4cc-30f1461499c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637f3e3e0>]}
[0m08:15:20.281658 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:15:20.282359 [info ] [MainThread]: 
[0m08:15:20.300802 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:15:20.301036 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:15:20.301363 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:15:20.301526 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:15:20.301614 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:15:20.303199 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:15:20.303464 [debug] [Thread-1 (]: finished collecting timing info
[0m08:15:20.303897 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:15:20.329400 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:15:20.329664 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:15:20.330508 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:15:21.110078 [debug] [Thread-1 (]: finished collecting timing info
[0m08:15:21.110776 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:15:21.111204 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c1cd67-eb99-45c4-b4cc-30f1461499c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637d7bc70>]}
[0m08:15:21.111748 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.81s]
[0m08:15:21.112393 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:15:21.114174 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:15:21.114456 [info ] [MainThread]: 
[0m08:15:21.114673 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.79 seconds (1.79s).
[0m08:15:21.114867 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:15:21.114995 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:15:21.115155 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:15:21.122669 [info ] [MainThread]: 
[0m08:15:21.122907 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:15:21.123095 [info ] [MainThread]: 
[0m08:15:21.123284 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:15:21.123470 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:15:21.123634 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:15:21.123839 [info ] [MainThread]: 
[0m08:15:21.124027 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:15:21.124333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637ef3880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637e73940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa637d4b640>]}
[0m08:15:21.124614 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:18:15.094675 | 2513ef28-072c-41ca-a5f5-2d6c539ea0ba ==============================
[0m08:18:15.094684 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:18:15.094901 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:18:15.094987 [debug] [MainThread]: Tracking: tracking
[0m08:18:15.096975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49270c85b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49270c86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49270c8790>]}
[0m08:18:15.122664 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:18:15.122863 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:18:15.127291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2513ef28-072c-41ca-a5f5-2d6c539ea0ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926f5a680>]}
[0m08:18:15.132682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2513ef28-072c-41ca-a5f5-2d6c539ea0ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926ec3eb0>]}
[0m08:18:15.132972 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:18:15.133133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2513ef28-072c-41ca-a5f5-2d6c539ea0ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926ec3f40>]}
[0m08:18:15.134062 [info ] [MainThread]: 
[0m08:18:15.134533 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:18:15.135262 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:18:15.135436 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:18:15.644856 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:18:15.645135 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:18:16.079421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2513ef28-072c-41ca-a5f5-2d6c539ea0ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926f9a440>]}
[0m08:18:16.080280 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:18:16.080700 [info ] [MainThread]: 
[0m08:18:16.099438 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:18:16.099679 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:18:16.100040 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:18:16.100164 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:18:16.100244 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:18:16.101639 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:18:16.101843 [debug] [Thread-1 (]: finished collecting timing info
[0m08:18:16.101928 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:18:16.126790 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:18:16.127115 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:18:16.128243 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:18:16.800890 [debug] [Thread-1 (]: finished collecting timing info
[0m08:18:16.801626 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:18:16.802067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2513ef28-072c-41ca-a5f5-2d6c539ea0ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926db3bb0>]}
[0m08:18:16.802639 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.70s]
[0m08:18:16.803324 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:18:16.804586 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:18:16.804898 [info ] [MainThread]: 
[0m08:18:16.805084 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.67 seconds (1.67s).
[0m08:18:16.805295 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:18:16.805394 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:18:16.805466 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:18:16.811443 [info ] [MainThread]: 
[0m08:18:16.811674 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:18:16.811860 [info ] [MainThread]: 
[0m08:18:16.812063 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:18:16.812253 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:18:16.812406 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:18:16.812616 [info ] [MainThread]: 
[0m08:18:16.812781 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:18:16.813129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49270cb370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926ec3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4926d83ac0>]}
[0m08:18:16.813346 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:20:36.633939 | 72db6499-f4f3-430d-8729-f06d12409094 ==============================
[0m08:20:36.633947 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:20:36.634158 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:20:36.634242 [debug] [MainThread]: Tracking: tracking
[0m08:20:36.635807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc100b05b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc100b06d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc100b0790>]}
[0m08:20:36.663362 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:20:36.663552 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:20:36.668031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '72db6499-f4f3-430d-8729-f06d12409094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0ff0a920>]}
[0m08:20:36.673461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72db6499-f4f3-430d-8729-f06d12409094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0fef4130>]}
[0m08:20:36.673704 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:20:36.673883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72db6499-f4f3-430d-8729-f06d12409094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0fef40a0>]}
[0m08:20:36.674754 [info ] [MainThread]: 
[0m08:20:36.675260 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:20:36.676050 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:20:36.676216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:20:37.175756 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:20:37.176219 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:20:37.537854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72db6499-f4f3-430d-8729-f06d12409094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0ff4ac80>]}
[0m08:20:37.538767 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:20:37.539248 [info ] [MainThread]: 
[0m08:20:37.557248 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:20:37.557530 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:20:37.557964 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:20:37.558123 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:20:37.558214 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:20:37.559715 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:20:37.559911 [debug] [Thread-1 (]: finished collecting timing info
[0m08:20:37.559995 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:20:37.585762 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:20:37.586163 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:20:37.587071 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:20:38.298786 [debug] [Thread-1 (]: finished collecting timing info
[0m08:20:38.299477 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:20:38.299907 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72db6499-f4f3-430d-8729-f06d12409094', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0fd8b790>]}
[0m08:20:38.300468 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.74s]
[0m08:20:38.301133 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:20:38.302901 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:20:38.303207 [info ] [MainThread]: 
[0m08:20:38.303417 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.63 seconds (1.63s).
[0m08:20:38.303571 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:20:38.303714 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:20:38.303830 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:20:38.310892 [info ] [MainThread]: 
[0m08:20:38.311219 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:20:38.311481 [info ] [MainThread]: 
[0m08:20:38.311698 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:20:38.311889 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:20:38.312058 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:20:38.312209 [info ] [MainThread]: 
[0m08:20:38.312377 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:20:38.312607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc100b05b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0fe73040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc0fd5bc10>]}
[0m08:20:38.312768 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 08:36:21.302796 | ebb80f28-a17d-4276-8ba6-5c0656073d5f ==============================
[0m08:36:21.302807 [info ] [MainThread]: Running with dbt=1.2.1
[0m08:36:21.303064 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m08:36:21.303165 [debug] [MainThread]: Tracking: tracking
[0m08:36:21.304945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efe645b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efe646d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efe64790>]}
[0m08:36:21.333523 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:36:21.333684 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:36:21.338406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ebb80f28-a17d-4276-8ba6-5c0656073d5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcc80d0>]}
[0m08:36:21.344188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ebb80f28-a17d-4276-8ba6-5c0656073d5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcac5e0>]}
[0m08:36:21.344464 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m08:36:21.344635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebb80f28-a17d-4276-8ba6-5c0656073d5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcac670>]}
[0m08:36:21.345793 [info ] [MainThread]: 
[0m08:36:21.346301 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:36:21.347157 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m08:36:21.347456 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:36:21.881775 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m08:36:21.882246 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:36:22.264410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ebb80f28-a17d-4276-8ba6-5c0656073d5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcac2b0>]}
[0m08:36:22.265338 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m08:36:22.265839 [info ] [MainThread]: 
[0m08:36:22.282965 [debug] [Thread-1 (]: Began running node model.project.customers
[0m08:36:22.283202 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.customers .............................. [RUN]
[0m08:36:22.283586 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.customers"
[0m08:36:22.283771 [debug] [Thread-1 (]: Began compiling node model.project.customers
[0m08:36:22.283958 [debug] [Thread-1 (]: Compiling model.project.customers
[0m08:36:22.285673 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.customers"
[0m08:36:22.286109 [debug] [Thread-1 (]: finished collecting timing info
[0m08:36:22.286229 [debug] [Thread-1 (]: Began executing node model.project.customers
[0m08:36:22.313773 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.customers"
[0m08:36:22.314122 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:36:22.315080 [debug] [Thread-1 (]: On model.project.customers: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.customers"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),

final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


[0m08:36:22.959429 [debug] [Thread-1 (]: finished collecting timing info
[0m08:36:22.960102 [debug] [Thread-1 (]: Database Error in model customers (models/customers.sql)
  Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/customers.sql
[0m08:36:22.960416 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebb80f28-a17d-4276-8ba6-5c0656073d5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efccab60>]}
[0m08:36:22.960993 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.customers ..................... [[31mERROR[0m in 0.68s]
[0m08:36:22.961573 [debug] [Thread-1 (]: Finished running node model.project.customers
[0m08:36:22.963342 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m08:36:22.963634 [info ] [MainThread]: 
[0m08:36:22.963800 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m08:36:22.963984 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:36:22.964092 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m08:36:22.964175 [debug] [MainThread]: Connection 'model.project.customers' was properly closed.
[0m08:36:22.969923 [info ] [MainThread]: 
[0m08:36:22.970298 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m08:36:22.970524 [info ] [MainThread]: 
[0m08:36:22.970837 [error] [MainThread]: [33mDatabase Error in model customers (models/customers.sql)[0m
[0m08:36:22.971194 [error] [MainThread]:   Access Denied: Table dbt-tutorial:jaffle_shop.customers: User does not have permission to query table dbt-tutorial:jaffle_shop.customers, or perhaps it does not exist in location EU.
[0m08:36:22.971446 [error] [MainThread]:   compiled SQL at target/run/project/models/customers.sql
[0m08:36:22.971699 [info ] [MainThread]: 
[0m08:36:22.972073 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m08:36:22.972419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcac340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efcac3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f23efb0bd90>]}
[0m08:36:22.972633 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 09:45:30.106227 | 9be86c74-1b71-46c7-b0ce-eea36260fada ==============================
[0m09:45:30.106237 [info ] [MainThread]: Running with dbt=1.2.1
[0m09:45:30.106517 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:45:30.106603 [debug] [MainThread]: Tracking: tracking
[0m09:45:30.108054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f6885b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f6886d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f688790>]}
[0m09:45:30.133296 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m09:45:30.133565 [debug] [MainThread]: Partial parsing: added file: project://models/publications.sql
[0m09:45:30.133694 [debug] [MainThread]: Partial parsing: deleted file: project://models/customers.sql
[0m09:45:30.144473 [debug] [MainThread]: 1699: static parser successfully parsed publications.sql
[0m09:45:30.161024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9be86c74-1b71-46c7-b0ce-eea36260fada', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90e301d80>]}
[0m09:45:30.165963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9be86c74-1b71-46c7-b0ce-eea36260fada', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f453f40>]}
[0m09:45:30.166266 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m09:45:30.166487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9be86c74-1b71-46c7-b0ce-eea36260fada', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f4a9a20>]}
[0m09:45:30.167375 [info ] [MainThread]: 
[0m09:45:30.167826 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:45:30.168677 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m09:45:30.168871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:45:30.706579 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m09:45:30.707081 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:45:31.079589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9be86c74-1b71-46c7-b0ce-eea36260fada', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f51a620>]}
[0m09:45:31.080585 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m09:45:31.081116 [info ] [MainThread]: 
[0m09:45:31.099461 [debug] [Thread-1 (]: Began running node model.project.publications
[0m09:45:31.099695 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.publications ........................... [RUN]
[0m09:45:31.100058 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.publications"
[0m09:45:31.100188 [debug] [Thread-1 (]: Began compiling node model.project.publications
[0m09:45:31.100268 [debug] [Thread-1 (]: Compiling model.project.publications
[0m09:45:31.102853 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.publications"
[0m09:45:31.103044 [debug] [Thread-1 (]: finished collecting timing info
[0m09:45:31.103127 [debug] [Thread-1 (]: Began executing node model.project.publications
[0m09:45:31.129097 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.publications"
[0m09:45:31.129478 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:45:31.130311 [debug] [Thread-1 (]: On model.project.publications: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.publications"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`publications`
  OPTIONS()
  as SELECT * FROM `patents-public-data.google_patents_research.publications_201710` LIMIT 1000;


[0m09:45:32.025243 [debug] [Thread-1 (]: finished collecting timing info
[0m09:45:32.026085 [debug] [Thread-1 (]: Database Error in model publications (models/publications.sql)
  Access Denied: Table patents-public-data:google_patents_research.publications_201710: User does not have permission to query table patents-public-data:google_patents_research.publications_201710, or perhaps it does not exist in location EU.
  compiled SQL at target/run/project/models/publications.sql
[0m09:45:32.026586 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9be86c74-1b71-46c7-b0ce-eea36260fada', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90e3bb6a0>]}
[0m09:45:32.027212 [error] [Thread-1 (]: 1 of 1 ERROR creating view model dbtbigquerytest.publications .................. [[31mERROR[0m in 0.93s]
[0m09:45:32.028032 [debug] [Thread-1 (]: Finished running node model.project.publications
[0m09:45:32.029455 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:45:32.029700 [info ] [MainThread]: 
[0m09:45:32.029885 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.86 seconds (1.86s).
[0m09:45:32.030080 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:45:32.030170 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m09:45:32.030250 [debug] [MainThread]: Connection 'model.project.publications' was properly closed.
[0m09:45:32.035935 [info ] [MainThread]: 
[0m09:45:32.036173 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:45:32.036362 [info ] [MainThread]: 
[0m09:45:32.036518 [error] [MainThread]: [33mDatabase Error in model publications (models/publications.sql)[0m
[0m09:45:32.036684 [error] [MainThread]:   Access Denied: Table patents-public-data:google_patents_research.publications_201710: User does not have permission to query table patents-public-data:google_patents_research.publications_201710, or perhaps it does not exist in location EU.
[0m09:45:32.036841 [error] [MainThread]:   compiled SQL at target/run/project/models/publications.sql
[0m09:45:32.037025 [info ] [MainThread]: 
[0m09:45:32.037182 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:45:32.037464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f4507f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90f453b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd90e3cece0>]}
[0m09:45:32.037671 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 09:45:35.544998 | 2e5d39fa-2853-4e80-87fb-dddb39c0de86 ==============================
[0m09:45:35.545009 [info ] [MainThread]: Running with dbt=1.2.1
[0m09:45:35.545253 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'compile': False, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m09:45:35.545342 [debug] [MainThread]: Tracking: tracking
[0m09:45:35.546851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f73c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f73c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f73c820>]}
[0m09:45:35.571858 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:45:35.572014 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:45:35.576202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e5d39fa-2853-4e80-87fb-dddb39c0de86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f61c0d0>]}
[0m09:45:35.577237 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m09:45:35.577341 [info ] [MainThread]: Building catalog
[0m09:45:35.577615 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:45:36.040979 [debug] [ThreadPool]: Acquiring new bigquery connection "bt-pp-cus-c84f.information_schema"
[0m09:45:36.053563 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:45:36.054521 [debug] [ThreadPool]: On bt-pp-cus-c84f.information_schema: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "connection_name": "bt-pp-cus-c84f.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.__TABLES__
        where (upper(dataset_id) = upper('dbtbigquerytest'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m09:45:38.568292 [info ] [MainThread]: Catalog written to /usr/app/dbt-bigquery/dbt/project/target/catalog.json
[0m09:45:38.569013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f73c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f676bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3b2f676bf0>]}
[0m09:45:38.569453 [debug] [MainThread]: Flushing usage events
[0m09:45:39.016437 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m09:45:39.016894 [debug] [MainThread]: Connection 'bt-pp-cus-c84f.information_schema' was properly closed.


============================== 2022-09-02 09:47:58.613757 | d838cbdd-274e-4f4b-b981-d5d66ce718db ==============================
[0m09:47:58.613766 [info ] [MainThread]: Running with dbt=1.2.1
[0m09:47:58.613977 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m09:47:58.614061 [debug] [MainThread]: Tracking: tracking
[0m09:47:58.616078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3167785b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3167786d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff316778790>]}
[0m09:47:58.641397 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m09:47:58.641646 [debug] [MainThread]: Partial parsing: added file: project://models/test.sql
[0m09:47:58.641733 [debug] [MainThread]: Partial parsing: deleted file: project://models/publications.sql
[0m09:47:58.651827 [debug] [MainThread]: 1699: static parser successfully parsed test.sql
[0m09:47:58.668009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd838cbdd-274e-4f4b-b981-d5d66ce718db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3153de290>]}
[0m09:47:58.673044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd838cbdd-274e-4f4b-b981-d5d66ce718db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3165b7be0>]}
[0m09:47:58.673327 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m09:47:58.673475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd838cbdd-274e-4f4b-b981-d5d66ce718db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3165b7bb0>]}
[0m09:47:58.674405 [info ] [MainThread]: 
[0m09:47:58.674818 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:47:58.675675 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m09:47:58.675878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:59.164812 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m09:47:59.165556 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:47:59.553836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd838cbdd-274e-4f4b-b981-d5d66ce718db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3165f2680>]}
[0m09:47:59.554896 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m09:47:59.555468 [info ] [MainThread]: 
[0m09:47:59.572929 [debug] [Thread-1 (]: Began running node model.project.test
[0m09:47:59.573165 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.test ................................... [RUN]
[0m09:47:59.573495 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.test"
[0m09:47:59.573632 [debug] [Thread-1 (]: Began compiling node model.project.test
[0m09:47:59.573723 [debug] [Thread-1 (]: Compiling model.project.test
[0m09:47:59.576357 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.test"
[0m09:47:59.576542 [debug] [Thread-1 (]: finished collecting timing info
[0m09:47:59.576638 [debug] [Thread-1 (]: Began executing node model.project.test
[0m09:47:59.602232 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.test"
[0m09:47:59.602535 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:47:59.603388 [debug] [Thread-1 (]: On model.project.test: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.test"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`test`
  OPTIONS()
  as select 1 as num;


[0m09:48:00.967890 [debug] [Thread-1 (]: finished collecting timing info
[0m09:48:00.968265 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd838cbdd-274e-4f4b-b981-d5d66ce718db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff31677b0d0>]}
[0m09:48:00.968535 [info ] [Thread-1 (]: 1 of 1 OK created view model dbtbigquerytest.test .............................. [[32mOK[0m in 1.39s]
[0m09:48:00.968791 [debug] [Thread-1 (]: Finished running node model.project.test
[0m09:48:00.970212 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m09:48:00.970511 [info ] [MainThread]: 
[0m09:48:00.970721 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.30 seconds (2.30s).
[0m09:48:00.970887 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:48:00.970984 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m09:48:00.971089 [debug] [MainThread]: Connection 'model.project.test' was properly closed.
[0m09:48:00.976454 [info ] [MainThread]: 
[0m09:48:00.976694 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:48:00.976904 [info ] [MainThread]: 
[0m09:48:00.977061 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:48:00.977335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3165b7f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3165b77f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff315495000>]}
[0m09:48:00.977566 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 09:48:04.443609 | 5533a9da-907b-4f08-94ee-acb80da6e5ce ==============================
[0m09:48:04.443619 [info ] [MainThread]: Running with dbt=1.2.1
[0m09:48:04.443835 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'compile': False, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m09:48:04.443935 [debug] [MainThread]: Tracking: tracking
[0m09:48:04.445450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b75605b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b75606d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b7560790>]}
[0m09:48:04.470253 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:48:04.470407 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:48:04.474675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5533a9da-907b-4f08-94ee-acb80da6e5ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b73ee6e0>]}
[0m09:48:04.476182 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m09:48:04.476384 [info ] [MainThread]: Building catalog
[0m09:48:04.476788 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:48:04.983603 [debug] [ThreadPool]: Acquiring new bigquery connection "bt-pp-cus-c84f.information_schema"
[0m09:48:04.997932 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:48:04.998853 [debug] [ThreadPool]: On bt-pp-cus-c84f.information_schema: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "connection_name": "bt-pp-cus-c84f.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.__TABLES__
        where (upper(dataset_id) = upper('dbtbigquerytest'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m09:48:07.398542 [info ] [MainThread]: Catalog written to /usr/app/dbt-bigquery/dbt/project/target/catalog.json
[0m09:48:07.398834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b75605b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b73bbaf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f95b73bba90>]}
[0m09:48:07.399006 [debug] [MainThread]: Flushing usage events
[0m09:48:07.847936 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m09:48:07.848393 [debug] [MainThread]: Connection 'bt-pp-cus-c84f.information_schema' was properly closed.


============================== 2022-09-02 13:59:49.250135 | 59c69ea0-78f4-4339-9df8-8bd7f6a3ecce ==============================
[0m13:59:49.250145 [info ] [MainThread]: Running with dbt=1.2.1
[0m13:59:49.250359 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m13:59:49.250445 [debug] [MainThread]: Tracking: tracking
[0m13:59:49.251917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7f305b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7f306d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7f30700>]}
[0m13:59:49.277566 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:59:49.277732 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:59:49.281760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59c69ea0-78f4-4339-9df8-8bd7f6a3ecce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7db00d0>]}
[0m13:59:49.286540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59c69ea0-78f4-4339-9df8-8bd7f6a3ecce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d8c490>]}
[0m13:59:49.286729 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m13:59:49.286876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59c69ea0-78f4-4339-9df8-8bd7f6a3ecce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d8c520>]}
[0m13:59:49.287713 [info ] [MainThread]: 
[0m13:59:49.288159 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:59:49.288847 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m13:59:49.288996 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:49.803220 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m13:59:49.803541 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:50.207829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59c69ea0-78f4-4339-9df8-8bd7f6a3ecce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d8c190>]}
[0m13:59:50.208891 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m13:59:50.209451 [info ] [MainThread]: 
[0m13:59:50.226890 [debug] [Thread-1 (]: Began running node model.project.test
[0m13:59:50.227121 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.test ................................... [RUN]
[0m13:59:50.227456 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.test"
[0m13:59:50.227579 [debug] [Thread-1 (]: Began compiling node model.project.test
[0m13:59:50.227657 [debug] [Thread-1 (]: Compiling model.project.test
[0m13:59:50.229056 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.test"
[0m13:59:50.229235 [debug] [Thread-1 (]: finished collecting timing info
[0m13:59:50.229315 [debug] [Thread-1 (]: Began executing node model.project.test
[0m13:59:50.254816 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.test"
[0m13:59:50.255108 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:59:50.255963 [debug] [Thread-1 (]: On model.project.test: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.test"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`test`
  OPTIONS()
  as select 1 as num;


[0m13:59:51.314527 [debug] [Thread-1 (]: finished collecting timing info
[0m13:59:51.314868 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59c69ea0-78f4-4339-9df8-8bd7f6a3ecce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d7bf70>]}
[0m13:59:51.315097 [info ] [Thread-1 (]: 1 of 1 OK created view model dbtbigquerytest.test .............................. [[32mOK[0m in 1.09s]
[0m13:59:51.315345 [debug] [Thread-1 (]: Finished running node model.project.test
[0m13:59:51.316802 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m13:59:51.317082 [info ] [MainThread]: 
[0m13:59:51.317271 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.03 seconds (2.03s).
[0m13:59:51.317468 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:59:51.317582 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m13:59:51.317664 [debug] [MainThread]: Connection 'model.project.test' was properly closed.
[0m13:59:51.322799 [info ] [MainThread]: 
[0m13:59:51.323011 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:59:51.323230 [info ] [MainThread]: 
[0m13:59:51.323419 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:59:51.323704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d8c340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7f33730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe3e7d7b760>]}
[0m13:59:51.323951 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 13:59:54.765745 | c5660669-9c48-4fa5-a5d9-02fc0384ebda ==============================
[0m13:59:54.765754 [info ] [MainThread]: Running with dbt=1.2.1
[0m13:59:54.766165 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'compile': False, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m13:59:54.766274 [debug] [MainThread]: Tracking: tracking
[0m13:59:54.767866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f983789c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f983789c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f983789c790>]}
[0m13:59:54.794464 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:59:54.794622 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:59:54.798852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c5660669-9c48-4fa5-a5d9-02fc0384ebda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98376e80d0>]}
[0m13:59:54.800465 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m13:59:54.800671 [info ] [MainThread]: Building catalog
[0m13:59:54.801071 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:59:55.278092 [debug] [ThreadPool]: Acquiring new bigquery connection "bt-pp-cus-c84f.information_schema"
[0m13:59:55.294924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:55.295819 [debug] [ThreadPool]: On bt-pp-cus-c84f.information_schema: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "connection_name": "bt-pp-cus-c84f.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.__TABLES__
        where (upper(dataset_id) = upper('dbtbigquerytest'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m13:59:58.720410 [info ] [MainThread]: Catalog written to /usr/app/dbt-bigquery/dbt/project/target/catalog.json
[0m13:59:58.720677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9839356ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98376afa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98376af850>]}
[0m13:59:58.720857 [debug] [MainThread]: Flushing usage events
[0m13:59:59.159455 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m13:59:59.159913 [debug] [MainThread]: Connection 'bt-pp-cus-c84f.information_schema' was properly closed.


============================== 2022-09-02 14:00:41.029386 | 528e21ee-dbab-4bb6-acfd-d2653df42fd3 ==============================
[0m14:00:41.029412 [info ] [MainThread]: Running with dbt=1.2.1
[0m14:00:41.029690 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m14:00:41.029794 [debug] [MainThread]: Tracking: tracking
[0m14:00:41.031445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d922c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d922c6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d922c790>]}
[0m14:00:41.056257 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:00:41.056462 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:00:41.060751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '528e21ee-dbab-4bb6-acfd-d2653df42fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d908e890>]}
[0m14:00:41.066473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '528e21ee-dbab-4bb6-acfd-d2653df42fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d90780d0>]}
[0m14:00:41.066731 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 285 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
[0m14:00:41.066892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '528e21ee-dbab-4bb6-acfd-d2653df42fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d9078100>]}
[0m14:00:41.067783 [info ] [MainThread]: 
[0m14:00:41.068243 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m14:00:41.068995 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f"
[0m14:00:41.069136 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:41.562055 [debug] [ThreadPool]: Acquiring new bigquery connection "list_bt-pp-cus-c84f_dbtbigquerytest"
[0m14:00:41.562777 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:00:41.927409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '528e21ee-dbab-4bb6-acfd-d2653df42fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d90cebf0>]}
[0m14:00:41.928471 [info ] [MainThread]: Concurrency: 1 threads (target='default')
[0m14:00:41.929021 [info ] [MainThread]: 
[0m14:00:41.948944 [debug] [Thread-1 (]: Began running node model.project.test
[0m14:00:41.949174 [info ] [Thread-1 (]: 1 of 1 START view model dbtbigquerytest.test ................................... [RUN]
[0m14:00:41.949499 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.project.test"
[0m14:00:41.949618 [debug] [Thread-1 (]: Began compiling node model.project.test
[0m14:00:41.949697 [debug] [Thread-1 (]: Compiling model.project.test
[0m14:00:41.951036 [debug] [Thread-1 (]: Writing injected SQL for node "model.project.test"
[0m14:00:41.951213 [debug] [Thread-1 (]: finished collecting timing info
[0m14:00:41.951291 [debug] [Thread-1 (]: Began executing node model.project.test
[0m14:00:41.977056 [debug] [Thread-1 (]: Writing runtime SQL for node "model.project.test"
[0m14:00:41.977360 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:00:41.978261 [debug] [Thread-1 (]: On model.project.test: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "node_id": "model.project.test"} */


  create or replace view `bt-pp-cus-c84f`.`dbtbigquerytest`.`test`
  OPTIONS()
  as select 1 as num;


[0m14:00:43.080976 [debug] [Thread-1 (]: finished collecting timing info
[0m14:00:43.081311 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '528e21ee-dbab-4bb6-acfd-d2653df42fd3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d8edabc0>]}
[0m14:00:43.081539 [info ] [Thread-1 (]: 1 of 1 OK created view model dbtbigquerytest.test .............................. [[32mOK[0m in 1.13s]
[0m14:00:43.081794 [debug] [Thread-1 (]: Finished running node model.project.test
[0m14:00:43.083096 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m14:00:43.083359 [info ] [MainThread]: 
[0m14:00:43.083586 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 2.02 seconds (2.02s).
[0m14:00:43.083797 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:00:43.083891 [debug] [MainThread]: Connection 'list_bt-pp-cus-c84f_dbtbigquerytest' was properly closed.
[0m14:00:43.083985 [debug] [MainThread]: Connection 'model.project.test' was properly closed.
[0m14:00:43.090256 [info ] [MainThread]: 
[0m14:00:43.090535 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:00:43.090818 [info ] [MainThread]: 
[0m14:00:43.091007 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:00:43.091322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d9078190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d9002d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9d922e1a0>]}
[0m14:00:43.091698 [debug] [MainThread]: Flushing usage events


============================== 2022-09-02 14:00:46.518128 | 9298d212-1e0d-41ec-b6ad-ea22021fbf75 ==============================
[0m14:00:46.518137 [info ] [MainThread]: Running with dbt=1.2.1
[0m14:00:46.518355 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'compile': False, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m14:00:46.518447 [debug] [MainThread]: Tracking: tracking
[0m14:00:46.519959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d5fc5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d5fc730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d5fc760>]}
[0m14:00:46.545761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:00:46.546017 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:00:46.550430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9298d212-1e0d-41ec-b6ad-ea22021fbf75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d4dc0d0>]}
[0m14:00:46.551748 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m14:00:46.551847 [info ] [MainThread]: Building catalog
[0m14:00:46.552095 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:00:47.011030 [debug] [ThreadPool]: Acquiring new bigquery connection "bt-pp-cus-c84f.information_schema"
[0m14:00:47.024994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:00:47.025882 [debug] [ThreadPool]: On bt-pp-cus-c84f.information_schema: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "connection_name": "bt-pp-cus-c84f.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.__TABLES__
        where (upper(dataset_id) = upper('dbtbigquerytest'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m14:00:50.833966 [info ] [MainThread]: Catalog written to /usr/app/dbt-bigquery/dbt/project/target/catalog.json
[0m14:00:50.834211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59f0670d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d4a3580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59d4a3ac0>]}
[0m14:00:50.834384 [debug] [MainThread]: Flushing usage events
[0m14:00:51.282211 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:00:51.282628 [debug] [MainThread]: Connection 'bt-pp-cus-c84f.information_schema' was properly closed.


============================== 2022-09-02 14:47:25.395766 | efe712cc-b840-424c-b3cc-019817da997b ==============================
[0m14:47:25.395776 [info ] [MainThread]: Running with dbt=1.2.1
[0m14:47:25.396049 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/usr/app/dbt-bigquery/dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/usr/app/dbt-bigquery/dbt/project', 'compile': False, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
[0m14:47:25.396162 [debug] [MainThread]: Tracking: tracking
[0m14:47:25.397791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f471a16c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f471a16c6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f471a16c790>]}
[0m14:47:25.422845 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:47:25.423149 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:47:25.428985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efe712cc-b840-424c-b3cc-019817da997b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4719faa8f0>]}
[0m14:47:25.430909 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
[0m14:47:25.431035 [info ] [MainThread]: Building catalog
[0m14:47:25.431450 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:47:25.928199 [debug] [ThreadPool]: Acquiring new bigquery connection "bt-pp-cus-c84f.information_schema"
[0m14:47:25.942822 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:47:25.943722 [debug] [ThreadPool]: On bt-pp-cus-c84f.information_schema: /* {"app": "dbt", "dbt_version": "1.2.1", "profile_name": "bigquery", "target_name": "default", "connection_name": "bt-pp-cus-c84f.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.__TABLES__
        where (upper(dataset_id) = upper('dbtbigquerytest'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `bt-pp-cus-c84f`.`dbtbigquerytest`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
[0m14:47:28.569865 [info ] [MainThread]: Catalog written to /usr/app/dbt-bigquery/dbt/project/target/catalog.json
[0m14:47:28.570113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f471a16c5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4719f77c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4719f77310>]}
[0m14:47:28.570338 [debug] [MainThread]: Flushing usage events
[0m14:47:29.029743 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:47:29.030210 [debug] [MainThread]: Connection 'bt-pp-cus-c84f.information_schema' was properly closed.
